# 测试分析助手设计文档

## 1. 文档目标
本设计文档定义一个可落地的“测试分析助手（Test Analysis Assistant）”，用于把分散的测试结果、日志、代码变更和历史失败模式，转化为可执行的测试结论与下一步动作。

该助手的核心目标不是“生成更多测试”，而是：
- 快速判断当前质量风险是否可接受。
- 定位失败根因与影响范围。
- 给出最小且高价值的测试改进建议。
- 形成结构化测试分析报告，支撑研发决策。

## 2. 在当前项目中的定位
当前仓库是中心编排的多智能体系统（`Orchestrator + AgentRegistry + Retriever`），测试以 `unittest` 为主，包含：
- 基础编排能力测试（`orchestrator/store/agents`）
- 端到端测试（`e2e`）
- 检索质量与回归测试（`paper_retrieval`）

测试分析助手应作为“测试执行后的决策层”，输入现有测试信号，输出分析报告与行动建议，不替代现有测试框架。

## 3. 设计原则
- 证据优先：只基于可验证证据（测试输出、文件差异、覆盖率、错误堆栈）下结论。
- 风险排序：先处理高影响/高概率问题。
- 最小动作：建议以最小改动降低最大风险。
- 可追踪：每条结论都能追溯到输入证据。
- 自动化友好：输出结构化，便于后续接入 CI。

## 4. 核心能力定义

### 4.1 运行状态分析
输入：测试命令输出、退出码、失败列表。
输出：
- 总体状态（pass / unstable / fail）
- 失败聚类（同类错误归并）
- 首要阻断项（blocking items）

### 4.2 根因与影响范围分析
输入：失败堆栈、最近代码变更、相关模块依赖。
输出：
- 疑似根因（按置信度排序）
- 影响面（模块、测试集、用户路径）
- 回归风险等级（P0/P1/P2）

### 4.3 测试质量分析
输入：现有测试用例、断言密度、覆盖缺口信号。
输出：
- 缺失的关键回归测试类型
- 低价值/重复测试识别
- 断言有效性问题（仅“能跑”但无业务约束）

### 4.4 改进行动建议
输入：以上所有分析结果。
输出：
- 可执行任务清单（按优先级）
- 每项任务的预期收益、成本和风险
- 推荐命令序列（先验证再修改）

## 5. 输入/输出契约

### 5.1 输入模型（抽象）
- `test_run`:
  - `command`
  - `exit_code`
  - `stdout/stderr`
  - `duration`
- `code_context`:
  - changed files
  - related modules
  - optional commit range
- `history`:
  - known flaky tests
  - historical failures
  - prior fixes

### 5.2 输出模型（核心）
- `status_summary`
- `findings[]`（severity、evidence、impact、confidence）
- `recommended_actions[]`（priority、effort、expected_gain）
- `verification_plan[]`（要执行的命令与通过标准）

## 6. 分析流程（建议实现）
1. 收集证据：执行并解析测试命令输出。
2. 建立故障图谱：按错误类型、模块和调用栈聚类。
3. 生成候选根因：结合代码上下文推断。
4. 风险分级：按影响面与概率评分。
5. 生成最小行动集：优先高收益低成本动作。
6. 输出标准化报告。

## 7. 报告模板（交付物）
每次分析应输出以下固定结构：

1. 执行概览
- 命令、耗时、通过率、失败数。

2. 关键发现（按严重度降序）
- `Severity`: P0/P1/P2
- `What`: 问题描述
- `Evidence`: 证据（测试名、报错片段、文件位置）
- `Impact`: 影响范围
- `Hypothesis`: 根因假设（含置信度）

3. 建议动作
- `Now`（立即执行）
- `Next`（下一迭代）
- `Later`（长期改进）

4. 验证计划
- 逐条验证命令
- 每条命令的通过判据

5. 残余风险
- 当前未覆盖风险与接受理由

## 8. 针对本仓库的首版落地方案（MVP）

### 8.1 范围
仅覆盖 `unittest` 场景：
- 解析 `python3 -m unittest -v` 输出
- 支持模块维度统计（`orchestrator/store/agents/e2e/paper_retrieval`）
- 输出 Markdown 测试分析报告

### 8.2 建议目录
- `src/multi_agent/test_analysis.py`：分析核心
- `tests/test_test_analysis.py`：分析器单测
- `docs/reports/`：分析报告输出目录

### 8.3 MVP 成功标准
- 能正确识别 pass/fail 与失败测试列表
- 能输出至少 3 类结论：阻断项、回归风险、建议动作
- 报告可直接被研发用于修复和验证

## 9. 质量度量（衡量助手是否“好用”）
- 分析准确率：根因 Top-1 命中率
- 行动有效率：建议动作被采用后的修复成功率
- 噪音率：低价值建议占比
- 周转时间：从测试失败到可执行结论的时长

## 10. 迭代路线图

### Phase 1（现在）
- 规则驱动分析（基于日志模式 + 文件映射）
- Markdown 报告输出

### Phase 2
- 引入历史失败知识库（flaky/已知问题）
- 风险评分模型

### Phase 3
- CI 集成（PR 自动生成测试分析报告）
- 建议动作自动生成“可执行命令包”

## 11. 边界与非目标
- 不直接替代人工做最终发布决策。
- 不在无证据情况下做确定性结论。
- 不默认改代码，只给可验证建议（除非显式要求自动修复）。

## 12. 最终结论
“最好的测试分析助手”应当是一个**证据驱动的质量决策层**：
- 能把测试信号转成行动。
- 能把行动绑定验证。
- 能在每次迭代后减少不确定性。

对于当前项目，建议从规则驱动 MVP 立即落地，并在后续迭代中接入历史知识与 CI 自动化，从“测试执行”升级到“测试决策”。
